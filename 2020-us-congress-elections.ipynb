{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set URL and directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://debatepolitics.com/forums/2020-us-congressional-elections.211/'\n",
    "p_dir = 'Downloaded_pages/2020-US-Congress-Elections/'\n",
    "\n",
    "pages_url = []\n",
    "thread_url = {}\n",
    "\n",
    "for i in range(1,7):\n",
    "    pages_url.append('page-'+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape data and load onto dictonary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Percentage of scrape complete 16%\n",
      "Percentage of scrape complete 33%\n",
      "Percentage of scrape complete 50%\n",
      "Percentage of scrape complete 66%\n",
      "Percentage of scrape complete 83%\n",
      "Percentage of scrape complete 100%\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for page in pages_url:\n",
    "    page = requests.get(base_url + page)\n",
    "    page_bs = BeautifulSoup(page.content, 'html.parser')\n",
    "    disc = page_bs.find('div', {'class': 'structItemContainer-group js-threadList'})\n",
    "    for thread in disc.find_all('div', {'class': 'structItem-title'}):\n",
    "        url_val = 'https://debatepolitics.com' + thread.find('a').get('href')\n",
    "        thread_url [thread.get_text()] = url_val\n",
    "    \n",
    "    sleep(2)\n",
    "    print(f'Percentage of scrape complete {int((i/len(pages_url))*100)}%')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape from each thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "len(thread_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 100%\n",
      "Percentage download completed 100%\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for title, url in thread_url.items():\n",
    "    thread_html = requests.get(url)\n",
    "    with open (p_dir + str(i) + '.html', 'w+') as f:\n",
    "        f.write(str(thread_html.content))\n",
    "    f.close()\n",
    "    print(f'Percentage download completed {int((i+1)/len(thread_url))*100}%')\n",
    "    i += 1\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "completed parsing 1.html\n",
      "completed parsing 2.html\n",
      "completed parsing 3.html\n",
      "completed parsing 4.html\n",
      "completed parsing 5.html\n",
      "completed parsing 6.html\n",
      "completed parsing 7.html\n",
      "completed parsing 8.html\n",
      "completed parsing 9.html\n",
      "completed parsing 10.html\n",
      "completed parsing 11.html\n",
      "completed parsing 12.html\n",
      "completed parsing 13.html\n",
      "completed parsing 14.html\n",
      "completed parsing 15.html\n",
      "completed parsing 16.html\n",
      "completed parsing 17.html\n",
      "completed parsing 18.html\n",
      "completed parsing 19.html\n",
      "completed parsing 20.html\n",
      "completed parsing 21.html\n",
      "completed parsing 22.html\n",
      "completed parsing 23.html\n",
      "completed parsing 24.html\n",
      "completed parsing 25.html\n",
      "completed parsing 26.html\n",
      "completed parsing 27.html\n",
      "completed parsing 28.html\n",
      "completed parsing 29.html\n",
      "completed parsing 30.html\n",
      "completed parsing 31.html\n",
      "completed parsing 32.html\n",
      "completed parsing 33.html\n",
      "completed parsing 34.html\n",
      "completed parsing 35.html\n",
      "completed parsing 36.html\n",
      "completed parsing 37.html\n",
      "completed parsing 38.html\n",
      "completed parsing 39.html\n",
      "completed parsing 40.html\n",
      "completed parsing 41.html\n",
      "completed parsing 42.html\n",
      "completed parsing 43.html\n",
      "completed parsing 44.html\n",
      "completed parsing 45.html\n",
      "completed parsing 46.html\n",
      "completed parsing 47.html\n",
      "completed parsing 48.html\n",
      "completed parsing 49.html\n",
      "completed parsing 50.html\n",
      "completed parsing 51.html\n",
      "completed parsing 52.html\n",
      "completed parsing 53.html\n",
      "completed parsing 54.html\n",
      "completed parsing 55.html\n",
      "completed parsing 56.html\n",
      "completed parsing 57.html\n",
      "completed parsing 58.html\n",
      "completed parsing 59.html\n",
      "completed parsing 60.html\n",
      "completed parsing 61.html\n",
      "completed parsing 62.html\n",
      "completed parsing 63.html\n",
      "completed parsing 64.html\n",
      "completed parsing 65.html\n",
      "completed parsing 66.html\n",
      "completed parsing 67.html\n",
      "completed parsing 68.html\n",
      "completed parsing 69.html\n",
      "completed parsing 70.html\n",
      "completed parsing 71.html\n",
      "completed parsing 72.html\n",
      "completed parsing 73.html\n",
      "completed parsing 74.html\n",
      "completed parsing 75.html\n",
      "completed parsing 76.html\n",
      "completed parsing 77.html\n",
      "completed parsing 78.html\n",
      "completed parsing 79.html\n",
      "completed parsing 80.html\n",
      "completed parsing 81.html\n",
      "completed parsing 82.html\n",
      "completed parsing 83.html\n",
      "completed parsing 84.html\n",
      "completed parsing 85.html\n",
      "completed parsing 86.html\n",
      "completed parsing 87.html\n",
      "completed parsing 88.html\n",
      "completed parsing 89.html\n",
      "completed parsing 90.html\n",
      "completed parsing 91.html\n",
      "completed parsing 92.html\n",
      "completed parsing 93.html\n",
      "completed parsing 94.html\n",
      "completed parsing 95.html\n",
      "completed parsing 96.html\n",
      "completed parsing 97.html\n",
      "completed parsing 98.html\n",
      "completed parsing 99.html\n",
      "completed parsing 100.html\n",
      "completed parsing 101.html\n",
      "completed parsing 102.html\n",
      "completed parsing 103.html\n",
      "completed parsing 104.html\n",
      "completed parsing 105.html\n",
      "completed parsing 106.html\n",
      "completed parsing 107.html\n",
      "completed parsing 108.html\n"
     ]
    }
   ],
   "source": [
    "thread_data = []\n",
    "\n",
    "for i in range(1, 109):\n",
    "    with open (p_dir + str(i) + '.html', 'r') as f:\n",
    "        dat = BeautifulSoup(f, 'html.parser')\n",
    "        dat_com  = dat.find('div', {'class' : 'block-container lbContainer'})\n",
    "        for comment in dat_com.find_all('article', {'class' : 'message message--post js-post js-inlineModContainer'}):\n",
    "            comment_msg = ''.join(re.findall('[^\\\\\\\\tn]+[a-zA-Z0-9,.!@?&$%]', comment.find('div', {'class' : 'bbWrapper'}).get_text()))\n",
    "            author = ''.join(re.findall('[^\\\\\\\\tn]+[a-zA-Z0-9,.!@?&$%]', comment.find('div', {'class' : 'message-userDetails'}).find('a', {'class' : 'username'}).get_text()))\n",
    "            # date = comment.find('header', {'class' : 'message-attribution message-attribution--split'}).find('a').get_text('u-concealed')\n",
    "            user_info = {}\n",
    "            for user_extra in comment.find_all('dl', {'class' : 'pairs pairs--justified'}):\n",
    "                user_info[user_extra.find('dt').get_text()] = ''.join(re.findall('[^\\\\\\\\nt]+[a-zA-Z0-9,.!@?&$%]',user_extra.find('dd').get_text()))\n",
    "            # print(user_info)\n",
    "            if 'Gender' in user_info and user_info['Gender'] != 'Undisclosed':\n",
    "                gender = user_info['Gender']\n",
    "            else:\n",
    "                gender = None\n",
    "            if 'Location' in user_info and user_info['Location'] != 'Undisclosed':\n",
    "                location = user_info['Location']\n",
    "            else:\n",
    "                location = None\n",
    "            if 'Political Leaning' in user_info and user_info['Political Leaning'] != 'Undisclosed':\n",
    "                polLean = user_info['Political Leaning']\n",
    "            else:\n",
    "                polLean = None\n",
    "            thread_data.append([author, comment_msg, i, gender, location, polLean])\n",
    "        \n",
    "        print(f'completed parsing {i}.html')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Poster                                            Content  Thread  \\\n",
       "0   Clicker III  Openly urging people to move to another state ...       1   \n",
       "1       Phys251  Clicker III saidOpenly urging people to move t...       1   \n",
       "2   swing_voter  RIGHT BIASThese media sources are moderately t...       1   \n",
       "3  it's just me  swing_voter saidRIGHT BIASThese media sources ...       1   \n",
       "4     Mr Person  Clicker III saidOpenly urging people to move t...       1   \n",
       "\n",
       "  Gender     Location Political_leaning  \n",
       "0   Male         None      Conservative  \n",
       "1   Male      Georgia  Slightly Liberal  \n",
       "2   None      'Murica        Independen  \n",
       "3   None         None              None  \n",
       "4   Male  Massachuset             Other  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Poster</th>\n      <th>Content</th>\n      <th>Thread</th>\n      <th>Gender</th>\n      <th>Location</th>\n      <th>Political_leaning</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Clicker III</td>\n      <td>Openly urging people to move to another state ...</td>\n      <td>1</td>\n      <td>Male</td>\n      <td>None</td>\n      <td>Conservative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Phys251</td>\n      <td>Clicker III saidOpenly urging people to move t...</td>\n      <td>1</td>\n      <td>Male</td>\n      <td>Georgia</td>\n      <td>Slightly Liberal</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>swing_voter</td>\n      <td>RIGHT BIASThese media sources are moderately t...</td>\n      <td>1</td>\n      <td>None</td>\n      <td>'Murica</td>\n      <td>Independen</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>it's just me</td>\n      <td>swing_voter saidRIGHT BIASThese media sources ...</td>\n      <td>1</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Mr Person</td>\n      <td>Clicker III saidOpenly urging people to move t...</td>\n      <td>1</td>\n      <td>Male</td>\n      <td>Massachuset</td>\n      <td>Other</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "clm_names = ['Poster' , 'Content', 'Thread', 'Gender', 'Location', 'Political_leaning']\n",
    "\n",
    "df = pd.DataFrame(thread_data, columns = clm_names)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('2020_US_Congress_Elections.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "a8329c364f44a091efdb92ea5f7f2984f29f748b54156e79c901c510f05a9ce2"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}