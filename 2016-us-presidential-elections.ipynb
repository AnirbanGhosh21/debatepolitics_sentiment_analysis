{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set URL and directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dir = 'Downloaded_pages/2012-US-Presidential-Election/'\n",
    "\n",
    "pages_url = []\n",
    "thread_url = {}\n",
    "\n",
    "for i in range(1,10):\n",
    "    pages_url.append(f'https://debatepolitics.com/search/36136/?page={i}&q=2012+US+Presidential+Election&t=post&c[child_nodes]=1&c[nodes][0]=153&o=replies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape data and load onto dictonary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Percentage of scrape complete 11%\n",
      "Percentage of scrape complete 22%\n",
      "Percentage of scrape complete 33%\n",
      "Percentage of scrape complete 44%\n",
      "Percentage of scrape complete 55%\n",
      "Percentage of scrape complete 66%\n",
      "Percentage of scrape complete 77%\n",
      "Percentage of scrape complete 88%\n",
      "Percentage of scrape complete 100%\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for page in pages_url:\n",
    "    page = requests.get(page)\n",
    "    page_bs = BeautifulSoup(page.content, 'html.parser')\n",
    "    disc = page_bs.find('div', {'class': 'block-container'})\n",
    "    for thread in disc.find_all('h3', {'class': 'contentRow-title'}):\n",
    "        url_val = 'https://debatepolitics.com' + thread.find('a').get('href')\n",
    "        thread_url [thread.get_text()] = url_val\n",
    "    \n",
    "    sleep(2)\n",
    "    print(f'Percentage of scrape complete {int((i/len(pages_url))*100)}%')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape from each thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "len(thread_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 0%\n",
      "Percentage download completed 100%\n",
      "Percentage download completed 100%\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for title, url in thread_url.items():\n",
    "    thread_html = requests.get(url)\n",
    "    with open (p_dir + str(i) + '.html', 'w+') as f:\n",
    "        f.write(str(thread_html.content))\n",
    "    f.close()\n",
    "    print(f'Percentage download completed {int((i+1)/len(thread_url))*100}%')\n",
    "    i += 1\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "completed parsing 1.html\n",
      "completed parsing 2.html\n",
      "completed parsing 3.html\n",
      "completed parsing 4.html\n",
      "completed parsing 5.html\n",
      "completed parsing 6.html\n",
      "completed parsing 7.html\n",
      "completed parsing 8.html\n",
      "completed parsing 9.html\n",
      "completed parsing 10.html\n",
      "completed parsing 11.html\n",
      "completed parsing 12.html\n",
      "completed parsing 13.html\n",
      "completed parsing 14.html\n",
      "completed parsing 15.html\n",
      "completed parsing 16.html\n",
      "completed parsing 17.html\n",
      "completed parsing 18.html\n",
      "completed parsing 19.html\n",
      "completed parsing 20.html\n",
      "completed parsing 21.html\n",
      "completed parsing 22.html\n",
      "completed parsing 23.html\n",
      "completed parsing 24.html\n",
      "completed parsing 25.html\n",
      "completed parsing 26.html\n",
      "completed parsing 27.html\n",
      "completed parsing 28.html\n",
      "completed parsing 29.html\n",
      "completed parsing 30.html\n",
      "completed parsing 31.html\n",
      "completed parsing 32.html\n",
      "completed parsing 33.html\n",
      "completed parsing 34.html\n",
      "completed parsing 35.html\n",
      "completed parsing 36.html\n",
      "completed parsing 37.html\n",
      "completed parsing 38.html\n",
      "completed parsing 39.html\n",
      "completed parsing 40.html\n",
      "completed parsing 41.html\n",
      "completed parsing 42.html\n",
      "completed parsing 43.html\n",
      "completed parsing 44.html\n"
     ]
    }
   ],
   "source": [
    "thread_data = []\n",
    "\n",
    "for i in range(1, 45):\n",
    "    with open (p_dir + str(i) + '.html', 'r') as f:\n",
    "        dat = BeautifulSoup(f, 'html.parser')\n",
    "        dat_com  = dat.find('div', {'class' : 'block-container lbContainer'})\n",
    "        for comment in dat_com.find_all('article', {'class' : 'message message--post js-post js-inlineModContainer'}):\n",
    "            comment_msg = ''.join(re.findall('[^\\\\\\\\tn]+[a-zA-Z0-9,.!@?&$%]', comment.find('div', {'class' : 'bbWrapper'}).get_text()))\n",
    "            author = ''.join(re.findall('[^\\\\\\\\tn]+[a-zA-Z0-9,.!@?&$%]', comment.find('div', {'class' : 'message-userDetails'}).find('a', {'class' : 'username'}).get_text()))\n",
    "            # date = comment.find('header', {'class' : 'message-attribution message-attribution--split'}).find('a').get_text('u-concealed')\n",
    "            user_info = {}\n",
    "            for user_extra in comment.find_all('dl', {'class' : 'pairs pairs--justified'}):\n",
    "                user_info[user_extra.find('dt').get_text()] = ''.join(re.findall('[^\\\\\\\\nt]+[a-zA-Z0-9,.!@?&$%]',user_extra.find('dd').get_text()))\n",
    "            # print(user_info)\n",
    "            if 'Gender' in user_info and user_info['Gender'] != 'Undisclosed':\n",
    "                gender = user_info['Gender']\n",
    "            else:\n",
    "                gender = None\n",
    "            if 'Location' in user_info and user_info['Location'] != 'Undisclosed':\n",
    "                location = user_info['Location']\n",
    "            else:\n",
    "                location = None\n",
    "            if 'Political Leaning' in user_info and user_info['Political Leaning'] != 'Undisclosed':\n",
    "                polLean = user_info['Political Leaning']\n",
    "            else:\n",
    "                polLean = None\n",
    "            thread_data.append([author, comment_msg, i, gender, location, polLean])\n",
    "        \n",
    "        print(f'completed parsing {i}.html')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Poster                                            Content  Thread  \\\n",
       "0         lpast  cpwill saidYou claimed to have been Pro-Life.C...       1   \n",
       "1        cpwill  lpast saidI was for the lionshare of my life u...       1   \n",
       "2         lpast  cpwill saidyes.  so as soon as it became expen...       1   \n",
       "3        cpwill  lpast saidLike I said...you would take the goo...       1   \n",
       "4  Sheik Yerbut  lpast saidLike I said...you would take the goo...       1   \n",
       "\n",
       "  Gender Location Political_leaning  \n",
       "0   Male      Fla        Independen  \n",
       "1   Male    USofA      Conservative  \n",
       "2   Male      Fla        Independen  \n",
       "3   Male    USofA      Conservative  \n",
       "4   None     None           Liberal  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Poster</th>\n      <th>Content</th>\n      <th>Thread</th>\n      <th>Gender</th>\n      <th>Location</th>\n      <th>Political_leaning</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>lpast</td>\n      <td>cpwill saidYou claimed to have been Pro-Life.C...</td>\n      <td>1</td>\n      <td>Male</td>\n      <td>Fla</td>\n      <td>Independen</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cpwill</td>\n      <td>lpast saidI was for the lionshare of my life u...</td>\n      <td>1</td>\n      <td>Male</td>\n      <td>USofA</td>\n      <td>Conservative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>lpast</td>\n      <td>cpwill saidyes.  so as soon as it became expen...</td>\n      <td>1</td>\n      <td>Male</td>\n      <td>Fla</td>\n      <td>Independen</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cpwill</td>\n      <td>lpast saidLike I said...you would take the goo...</td>\n      <td>1</td>\n      <td>Male</td>\n      <td>USofA</td>\n      <td>Conservative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sheik Yerbut</td>\n      <td>lpast saidLike I said...you would take the goo...</td>\n      <td>1</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Liberal</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "clm_names = ['Poster' , 'Content', 'Thread', 'Gender', 'Location', 'Political_leaning']\n",
    "\n",
    "df = pd.DataFrame(thread_data, columns = clm_names)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('2012_US_Presidential_Elections.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.8 64-bit ('cs109a': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a8329c364f44a091efdb92ea5f7f2984f29f748b54156e79c901c510f05a9ce2"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}